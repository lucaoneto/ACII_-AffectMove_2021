{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taks1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRGzmlr4jcd0"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from scipy.interpolate import CubicSpline\n",
        "import ast, sys\n",
        "from scipy.stats import iqr\n",
        "from sklearn.metrics import accuracy_score\n",
        "import glob\n",
        "from scipy import signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh9Y122ejlLk"
      },
      "source": [
        "def readData(path):\n",
        "  data_path = 'EmoPain/'+path+'/'\n",
        "  ret = []\n",
        "  files = glob.glob(data_path + '*txt')\n",
        "  tot_lun = len(files)\n",
        "\n",
        "  for number, file in enumerate(files): \n",
        "    sys.stdout.write(\"\\r computed {%d/ %d}\" % (number+1, tot_lun) )\n",
        "    sys.stdout.flush()\n",
        "\n",
        "    if '(' not in file and ')' not in file:\n",
        "      df = pd.read_csv(file, sep=',', decimal='.',header=None).T\n",
        "      diff = np.zeros((len(df),17))\n",
        "\n",
        "      for idf in range(17):\n",
        "        b = np.array([df.iloc[:,0:51:3].T.mean(), df.iloc[:,1:51:3].T.mean(), df.iloc[:,2:51:3].T.mean()])\n",
        "        f = np.asarray([df.iloc[:,idf*3], df.iloc[:,idf*3+1], df.iloc[:,idf*3+2]])\n",
        "        diff[:, idf] = computeEuclideanDistance(f,b)\n",
        "      \n",
        "      el_data = df.iloc[:,51:55].values\n",
        "      info = file.split('/P')[1].split('_')\n",
        "      if len(info) == 4:\n",
        "        person = int(info[0])\n",
        "        label = int(info[2])\n",
        "        exercise = int(info[-1].split('.txt')[0])\n",
        "        meta = np.array([person, label, exercise]) \n",
        "        meta = np.tile(meta, (len(diff), 1))\n",
        "        all_data = np.concatenate((meta,diff,el_data), axis=1)\n",
        "      else:\n",
        "        person = int(info[0])\n",
        "        exercise = int(info[-1].split('.txt')[0])\n",
        "        meta = np.array([person, exercise]) \n",
        "        meta = np.tile(meta, (len(diff), 1))\n",
        "        all_data = np.concatenate((meta,diff,el_data), axis=1)\n",
        "      \n",
        "      if len(ret) == 0:\n",
        "        ret = all_data\n",
        "      else:\n",
        "        ret = np.concatenate((ret, all_data), axis=0)\n",
        "  \n",
        "  print()\n",
        "  return pd.DataFrame(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqm27dH7jpMV"
      },
      "source": [
        "%%time\n",
        "X_train = readData('training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRls1im-JkU"
      },
      "source": [
        "%%time\n",
        "X_val = readData('validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9SaoQ82-OZt"
      },
      "source": [
        "%%time\n",
        "X_test = readData('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-VBYgB6u63U"
      },
      "source": [
        "X_train.to_csv('EmoPain/train.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_val.to_csv('EmoPain/val.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_test.to_csv('EmoPain/test.csv', sep=';', decimal='.', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpgpXWHJrHxt"
      },
      "source": [
        "X_train = pd.read_csv('EmoPain/train.csv', sep=';', decimal='.',header=0) \n",
        "X_val = pd.read_csv('EmoPain/val.csv', sep=';', decimal='.',header=0) \n",
        "X_test = pd.read_csv('EmoPain/test.csv', sep=';', decimal='.',header=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX8q_tk0FliK"
      },
      "source": [
        "def extractFeatures(features):\n",
        "  raw_features = 21\n",
        "  mean = features.mean().values\n",
        "  var = features.var().values\n",
        "  kurt = features.kurtosis().values\n",
        "  skew = features.skew().values\n",
        "  corr = features.corr().values[np.triu_indices(raw_features,k=1)]\n",
        "  mad = features.mad().values\n",
        "  sem = features.sem().values\n",
        "  arr = features.values\n",
        "  energy = np.sqrt(np.einsum('ij,ij->j',arr,arr))\n",
        "  iqr_ = iqr(arr,axis=0)\n",
        "  mi = features.min().values\n",
        "  ma = features.max().values\n",
        "  slopes = features.apply(lambda x: np.polyfit(features.index, x, 1)[0]).values\n",
        "\n",
        "  frq_info = []\n",
        "  for el in features[features.columns]:\n",
        "      f_ = features[el]\n",
        "      fft = np.fft.fft(f_)\n",
        "      amplitude_spectrum = np.abs(fft)\n",
        "      phase_angle = np.angle(f_)\n",
        "\n",
        "      frq_info.extend([amplitude_spectrum[0].real,phase_angle[0].real,np.max(np.abs(fft[1:])),np.argmax(fft[1:])])\n",
        "      frq_info.extend([pd.DataFrame(fft[1:]).abs().kurtosis().values[0],pd.DataFrame(fft[1:]).abs().skew().values[0], pd.DataFrame(fft[1:]).abs().mean(axis=0).values[0]])\n",
        "  \n",
        "  frq_info = np.asarray(frq_info)\n",
        "  return np.concatenate((mean,var,kurt,skew,corr,mad,sem,energy,iqr_,mi,ma,slopes,frq_info))\n",
        "\n",
        "def featureEngineering(X,test=False):\n",
        "  groups = X.groupby([X.person, X.exercise])\n",
        "  keys = list(groups.groups.keys())\n",
        "\n",
        "  n_groups = groups.ngroups\n",
        "  if test:\n",
        "    ret = np.zeros((n_groups,1178))\n",
        "  else:\n",
        "    ret = np.zeros((n_groups,1179))\n",
        "\n",
        "  for i in range(len(keys)):\n",
        "    sys.stdout.write(\"\\r computed {%d/ %d}\" % (i+1, n_groups) )\n",
        "    sys.stdout.flush()\n",
        "    g = groups.get_group(list(keys)[i])\n",
        "\n",
        "    if test:\n",
        "      features = g.iloc[:,2:]\n",
        "      labels = g.iloc[0,:2].values\n",
        "    else:\n",
        "      features = g.iloc[:,3:]\n",
        "      labels = g.iloc[0,:3].values\n",
        "\n",
        "    f_per_launch = []\n",
        "    for j in range(0,90,45):\n",
        "      f_computed = extractFeatures(features.iloc[j:j+90,:])\n",
        "      if len(f_per_launch) == 0:\n",
        "        f_per_launch = np.concatenate((labels,f_computed),axis=0)\n",
        "      else:\n",
        "        f_per_launch = np.concatenate((f_per_launch,f_computed),axis=0)\n",
        "\n",
        "    f_per_launch = f_per_launch.reshape(1,-1) \n",
        "    ret[i,:] = f_per_launch\n",
        "\n",
        "  print()\n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3ljrQEFlqh"
      },
      "source": [
        "%%time\n",
        "feat_train = featureEngineering(X_train,test=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h79EcqtHWo1"
      },
      "source": [
        "%%time\n",
        "feat_val = featureEngineering(X_val,test=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZFqX3AZIJm0"
      },
      "source": [
        "%%time\n",
        "feat_test = featureEngineering(X_test,test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxL1OKCLcLiq"
      },
      "source": [
        "feat_train = pd.DataFrame(feat_train)\n",
        "feat_val = pd.DataFrame(feat_val)\n",
        "feat_test = pd.DataFrame(feat_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDAPDgyfLWqg"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy=\"most_frequent\")\n",
        "\n",
        "a = imp.fit_transform(feat_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4cTftT_F5Cp"
      },
      "source": [
        "X_train = feat_train.copy()\n",
        "X_val = feat_val.copy()\n",
        "X_test = feat_test.copy()\n",
        "\n",
        "X_train.rename(columns={ X_train.columns[0]: \"person\",X_train.columns[1]: \"label\",X_train.columns[2]: \"exercise\"},inplace=True)\n",
        "X_val.rename(columns={ X_val.columns[0]: \"person\",X_val.columns[1]: \"label\",X_val.columns[2]: \"exercise\"},inplace=True)\n",
        "X_test.rename(columns={ X_test.columns[0]: \"person\",X_test.columns[1]: \"exercise\"},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFClP4budZFa"
      },
      "source": [
        "X_train.to_csv('EmoPain/feat_train.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_val.to_csv('EmoPain/feat_val.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_test.to_csv('EmoPain/feat_test.csv', sep=';', decimal='.', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxeSENpaXyd_"
      },
      "source": [
        "X_train = pd.read_csv('EmoPain/feat_train.csv', sep=';', decimal='.',header=0) \n",
        "X_val = pd.read_csv('EmoPain/feat_val.csv', sep=';', decimal='.',header=0) \n",
        "X_test = pd.read_csv('EmoPain/feat_test.csv', sep=';', decimal='.',header=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylj8dOpeF9fB"
      },
      "source": [
        "def norm(X, test=False):\n",
        "  groups = X.groupby(['person'])\n",
        "  ret = []\n",
        "  for name, g in groups:\n",
        "    if test:\n",
        "      s = g.iloc[:,2:]\n",
        "      scaler = preprocessing.StandardScaler().fit(s.values)\n",
        "      new_values = g.values\n",
        "      new_values[:,2:] = scaler.transform(s.values)\n",
        "      ret.append(new_values)\n",
        "    else:\n",
        "      s = g.iloc[:,3:]\n",
        "      scaler = preprocessing.StandardScaler().fit(s.values)\n",
        "      new_values = g.values\n",
        "      new_values[:,3:] = scaler.transform(s.values)\n",
        "      ret.append(new_values)\n",
        "\n",
        "  ret = pd.DataFrame(np.asarray(np.vstack(ret)))\n",
        "  ret.columns = X.columns  \n",
        "  return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww-MrGFm_Dix"
      },
      "source": [
        "%%time\n",
        "X_train = norm(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBrKhe2z_Dq7"
      },
      "source": [
        "%%time\n",
        "X_val = norm(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6bYxuHG0CR"
      },
      "source": [
        "%%time\n",
        "X_test = norm(X_test,test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMMqN0UVGYDD"
      },
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1c0kTe4JhHu"
      },
      "source": [
        "def leave_1_out(X):\n",
        "  grouped = X.groupby([X.person])\n",
        "  \n",
        "  for i, (name,group) in enumerate(grouped):\n",
        "    test = group.copy()\n",
        "    train = X.drop(test.index)\n",
        "    \n",
        "    yield train.index, test.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XapnOh8VMzHF"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=1000)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', ADASYN()],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(X_train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print('ACC:' , accuracy_score(X_val.label, y_pred))\n",
        "print('B_ACC:', balanced_accuracy_score(X_val.label, y_pred))\n",
        "print('f1:', f1_score(X_val.label, y_pred))\n",
        "print('MCC:', matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9C-bsiyMzLt"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3)) #11 e auto 34\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',50,75, sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler()],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(train, X_train.label)\n",
        "\n",
        "y_pred = clf.predict(val)\n",
        "print(accuracy_score(X_val.label, y_pred), balanced_accuracy_score(X_val.label, y_pred))\n",
        "print(f1_score(X_val.label, y_pred))\n",
        "print(matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVy9bV-MS_Iw"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', SMOTE(random_state=42)],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "print(clf.score(X_val.iloc[:,3:], X_val.label))\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print(accuracy_score(X_val.label, y_pred), balanced_accuracy_score(X_val.label, y_pred))\n",
        "print(f1_score(X_val.label, y_pred))\n",
        "print(matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjgbtyVZsTfo"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', SMOTETomek(random_state=42)],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "print(clf.score(X_val.iloc[:,3:], X_val.label))\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print(accuracy_score(X_val.label, y_pred), balanced_accuracy_score(X_val.label, y_pred))\n",
        "print(f1_score(X_val.label, y_pred))\n",
        "print(matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WN93GzwgJiF"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "print(clf.score(X_val.iloc[:,3:], X_val.label))\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print(accuracy_score(X_val.label, y_pred), balanced_accuracy_score(X_val.label, y_pred))\n",
        "print(f1_score(X_val.label, y_pred))\n",
        "print(matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGtzYYX2imF4"
      },
      "source": [
        "learning = pd.concat([X_train,X_val], axis=0)\n",
        "learning.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp8jniGnPVoI"
      },
      "source": [
        "Random Forest Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2ERVYGkg8r2"
      },
      "source": [
        "%%time\n",
        "n_features = learning.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "\n",
        "cv = leave_1_out(learning) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=-1)\n",
        "clf.fit(learning.iloc[:,3:], learning.label)\n",
        "y_pred = clf.predict(X_test.iloc[:,2:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku8I43tlzjhc"
      },
      "source": [
        "pd.DataFrame(y_pred).to_csv('EmoPain/predictionRF.csv', sep=';', decimal='.', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10IYRSzoPZLh"
      },
      "source": [
        "XGBOOST predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ths4RG_hPayf"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from scipy import stats\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "param_grid = {\n",
        "      'model__eta': [0.01,0.05,0.1,0.3],\n",
        "      'model__max_depth': [3,5,7,9],\n",
        "      'model__gamma': [0,0.1,0.2,0.3,0.4,0.5],\n",
        "      }\n",
        "\n",
        "\n",
        "model = xgb.XGBClassifier(n_estimators=1000)\n",
        "\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['model', model]]\n",
        "                       )\n",
        "cv = leave_1_out(X_learning)\n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=4,verbose=1)\n",
        "clf.fit(X_learning.iloc[:,3:], X_learning.label)\n",
        "xgboost_pred = clf.predict(X_test.iloc[:,2:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qo7tyMjQITh"
      },
      "source": [
        "pd.DataFrame(y_pred).to_csv('EmoPain/predictionXGBOOST.csv', sep=';', decimal='.', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}