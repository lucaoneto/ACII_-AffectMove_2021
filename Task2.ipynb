{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Task2_challengeV2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFpp3WCYFwfo"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from scipy.interpolate import CubicSpline\n",
        "import ast, sys\n",
        "from scipy.stats import iqr\n",
        "from sklearn.metrics import accuracy_score\n",
        "import glob\n",
        "from scipy import signal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzu_SgZtFwfs"
      },
      "source": [
        "def computeEuclideanDistance(b1, b2):\n",
        "    return np.sqrt( (b1[0,:]-b2[0,:])**2 + (b1[1,:]-b2[1,:])**2 + (b1[2,:]-b2[2,:])**2)\n",
        "\n",
        "def computeEuclideanDistanceAll(p1,p2):\n",
        "    return np.sqrt((p1-p2)**2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf8EOO4_Fwfv"
      },
      "source": [
        "def readData(path):\n",
        "    data_path = 'challenge/task2/'+path+'/'\n",
        "    ret = []\n",
        "    files = glob.glob(data_path + '*txt')\n",
        "    tot_lun = len(files)\n",
        "\n",
        "    for number, file in enumerate(files): \n",
        "        sys.stdout.write(\"\\r computed {%d/ %d}\" % (number, tot_lun) )\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "        df = pd.read_csv(file, sep=',', decimal='.',header=None).T\n",
        "        df.fillna(df.median(),inplace=True)\n",
        "        diff = np.zeros((len(df),17))\n",
        "\n",
        "        for idf in range(17):\n",
        "            b = np.array([df.iloc[:,1::3].T.mean(), df.iloc[:,2::3].T.mean(), df.iloc[:,3::3].T.mean()])\n",
        "            f = np.asarray([df.iloc[:,idf*3+1], df.iloc[:,idf*3+1+1], df.iloc[:,idf*3+2+1]])\n",
        "            diff[:, idf] = computeEuclideanDistance(f,b)\n",
        "        \n",
        "\n",
        "        info = file.split('\\\\')[-1].split('.txt')[0].split('_')\n",
        "        if len(info) == 4:\n",
        "            person = int(info[0])\n",
        "            exer_type = int(info[1])\n",
        "            label = int(info[2])\n",
        "            exercise = int(info[-1])\n",
        "            meta = np.array([person, exer_type, label, exercise]) \n",
        "            meta = np.tile(meta, (len(diff), 1))\n",
        "            all_data = np.concatenate((meta,diff), axis=1)\n",
        "        else:\n",
        "            person = int(info[0])\n",
        "            exercise = int(info[-1])\n",
        "            meta = np.array([person, exercise]) \n",
        "            meta = np.tile(meta, (len(diff), 1))\n",
        "            all_data = np.concatenate((meta,diff), axis=1)\n",
        "\n",
        "        if len(ret) == 0:\n",
        "            ret = all_data\n",
        "        else:\n",
        "            ret = np.concatenate((ret, all_data), axis=0)\n",
        "    \n",
        "    print()\n",
        "    return pd.DataFrame(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_PdyxRwFwfx"
      },
      "source": [
        "%%time\n",
        "X_train = readData('training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8eq1b9BFwf1"
      },
      "source": [
        "%%time\n",
        "X_val = readData('validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9SspcxnFwf3"
      },
      "source": [
        "%%time\n",
        "X_test = readData('test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVFN3xMcFwf4"
      },
      "source": [
        "X_train.rename(columns={ X_train.columns[0]: \"person\",X_train.columns[1]:\"type\",X_train.columns[2]: \"label\",X_train.columns[3]: \"exercise\"},inplace=True)\n",
        "X_val.rename(columns={ X_val.columns[0]: \"person\",X_val.columns[1]:\"type\", X_val.columns[2]: \"label\",X_val.columns[3]: \"exercise\"},inplace=True)\n",
        "X_test.rename(columns={ X_test.columns[0]: \"person\",X_test.columns[1]: \"exercise\"},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qElMSYBSFwf6"
      },
      "source": [
        "X_train.to_csv('challenge/task2/train.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_val.to_csv('challenge/task2/val.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_test.to_csv('challenge/task2/test.csv', sep=';', decimal='.', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ry58xISFwf8"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTem-H24Fwf-"
      },
      "source": [
        "from scipy.interpolate import interp1d, CubicSpline\n",
        "\n",
        "def sampleSameLenght(X,lenght):\n",
        "    groups = X.groupby([X.person, X.exercise]) \n",
        "    if lenght == None:\n",
        "        lenght = int(groups.size().mode())\n",
        "    ret = []\n",
        "    r, c = lenght, X.shape[1]\n",
        "    \n",
        "    for idg, (name, g) in enumerate(groups):\n",
        "        sys.stdout.write(\"\\r computed {%d/ %d}\" % (idg+1, groups.ngroups) )\n",
        "        sys.stdout.flush()\n",
        "        comodo = np.zeros((r,c))\n",
        "        comodo[:r,:3] = np.tile(g.iloc[0,:3].values, (r,1))\n",
        "\n",
        "        x = g.index\n",
        "        x_new = np.linspace(np.min(x),np.max(x), lenght)\n",
        "\n",
        "        for i in range(3,c):\n",
        "            y = g.iloc[:,i]\n",
        "            f = CubicSpline(x,y)\n",
        "\n",
        "            y_new = f(x_new)\n",
        "            comodo[:,i] = y_new\n",
        "\n",
        "        ret.append(comodo)\n",
        "\n",
        "    ret = pd.DataFrame(np.vstack(ret), columns=X.columns)\n",
        "    ret.sort_index(inplace=True)\n",
        "    ret.reset_index(drop=True, inplace=True)\n",
        "    print()\n",
        "    return ret, lenght"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1bREETJFwf_"
      },
      "source": [
        "%%time\n",
        "X_train, dim = sampleSameLenght(X_train,120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ft0-jxHFwgA"
      },
      "source": [
        "%%time\n",
        "X_val, _ = sampleSameLenght(X_val,dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndHNSjoPFwgB"
      },
      "source": [
        "%%time\n",
        "X_test, _ = sampleSameLenght(X_test,dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8JT_Dy4FwgH"
      },
      "source": [
        "def extractFeatures(features):\n",
        "    features.fillna(0,inplace=True)\n",
        "    raw_features = features.shape[1]\n",
        "    mean = features.mean().values\n",
        "    var = features.var().values\n",
        "    kurt = features.kurtosis().values\n",
        "    skew = features.skew().values\n",
        "    corr = features.corr().values[np.triu_indices(raw_features,k=1)]\n",
        "    mad = features.mad().values\n",
        "    sem = features.sem().values\n",
        "    arr = features.values\n",
        "    energy = np.sqrt(np.einsum('ij,ij->j',arr,arr))\n",
        "    iqr_ = iqr(arr,axis=0)\n",
        "    mi = features.min().values\n",
        "    ma = features.max().values\n",
        "    slopes = features.apply(lambda x: np.polyfit(features.index, x, 1)[0]).values\n",
        "\n",
        "    frq_info = []\n",
        "    for el in features[features.columns]:\n",
        "        f_ = features[el]\n",
        "        fft = np.fft.fft(f_)\n",
        "        amplitude_spectrum = np.abs(fft)\n",
        "        phase_angle = np.angle(f_)\n",
        "\n",
        "    frq_info.extend([amplitude_spectrum[0].real,phase_angle[0].real,np.max(np.abs(fft[1:])),np.argmax(fft[1:])])\n",
        "    frq_info.extend([pd.DataFrame(fft[1:]).abs().kurtosis().values[0],pd.DataFrame(fft[1:]).abs().skew().values[0], pd.DataFrame(fft[1:]).abs().mean(axis=0).values[0]])\n",
        "  \n",
        "    frq_info = np.asarray(frq_info)\n",
        "    ret = np.concatenate((mean,var,kurt,skew,corr,mad,sem,energy,iqr_,mi,ma,slopes,frq_info))#.reshape(1,-1) \n",
        "    return ret\n",
        "\n",
        "def featureEngineering(X,test=False):\n",
        "    if test:\n",
        "        groups = X.groupby([X.person, X.exercise])\n",
        "        keys = list(groups.groups.keys())\n",
        "        n_groups = groups.ngroups        \n",
        "        ret = np.zeros((n_groups,992))\n",
        "    else:\n",
        "        groups = X.groupby([X.person, X.label,X.exercise])\n",
        "        keys = list(groups.groups.keys())\n",
        "        n_groups = groups.ngroups   \n",
        "        ret = np.zeros((n_groups,994))\n",
        "\n",
        "    for i in range(len(keys)):\n",
        "        sys.stdout.write(\"\\r computed {%d/ %d}\" % (i+1, n_groups) )\n",
        "        sys.stdout.flush()\n",
        "        g = groups.get_group(list(keys)[i])\n",
        "\n",
        "        if test:\n",
        "            features = g.iloc[:,2:]\n",
        "            labels = g.iloc[0,:2].values\n",
        "        else:\n",
        "            features = g.iloc[:,4:]\n",
        "            labels = g.iloc[0,:4].values\n",
        "\n",
        "        f_per_launch = []\n",
        "        mid = round(len(features)/2)\n",
        "        step = round(mid/2)\n",
        "        \n",
        "        for j in range(0,len(features)-step,step):\n",
        "            f_computed = extractFeatures(features.iloc[j:j+mid,:])\n",
        "            if len(f_per_launch) == 0:\n",
        "                f_per_launch = np.concatenate((labels,f_computed),axis=0)\n",
        "            else:\n",
        "                f_per_launch = np.concatenate((f_per_launch,f_computed),axis=0)\n",
        "        \n",
        "        f_per_launch = f_per_launch.reshape(1,-1) \n",
        "        ret[i,:] = f_per_launch\n",
        "    print()\n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1bxPc_3FwgJ"
      },
      "source": [
        "%%time\n",
        "X_train = featureEngineering(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3OFyhrKFwgK"
      },
      "source": [
        "%%time\n",
        "X_val = featureEngineering(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuF7auzFwgM"
      },
      "source": [
        "%%time\n",
        "X_test = featureEngineering(X_test, test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6NVZplDFwgN"
      },
      "source": [
        "X_train = pd.DataFrame(X_train)\n",
        "X_val = pd.DataFrame(X_val)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "\n",
        "X_train.rename(columns={ X_train.columns[0]: \"person\",X_train.columns[1]:\"type\",X_train.columns[2]: \"label\",X_train.columns[3]: \"exercise\"},inplace=True)\n",
        "X_val.rename(columns={ X_val.columns[0]: \"person\",X_val.columns[1]:\"type\", X_val.columns[2]: \"label\",X_val.columns[3]: \"exercise\"},inplace=True)\n",
        "X_test.rename(columns={ X_test.columns[0]: \"person\",X_test.columns[1]: \"exercise\"},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbyqhJgYFwgN"
      },
      "source": [
        "X_train.to_csv('challenge/task2/train_feat.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_val.to_csv('challenge/task2/val_feat.csv', sep=';', decimal='.', index=False, header=True)\n",
        "X_test.to_csv('challenge/task2/test_feat.csv', sep=';', decimal='.', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjUGeHGeFwgO"
      },
      "source": [
        "X_train = pd.read_csv('task2/train_feat.csv', sep=';', decimal='.',header=0) \n",
        "X_val = pd.read_csv('challenge/task2/val_feat.csv', sep=';', decimal='.',header=0) \n",
        "X_test = pd.read_csv('task2/test_feat.csv', sep=';', decimal='.',header=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-SSF7RgFwgO"
      },
      "source": [
        "def norm(X, test=False):\n",
        "    groups = X.groupby(['person'])\n",
        "    ret = []\n",
        "    for name, g in groups:\n",
        "        if test:\n",
        "            s = g.iloc[:,2:]\n",
        "            scaler = preprocessing.StandardScaler().fit(s.values)\n",
        "            new_values = g.values\n",
        "            new_values[:,2:] = scaler.transform(s.values)\n",
        "            ret.append(new_values)\n",
        "        else:\n",
        "            s = g.iloc[:,3:]\n",
        "            scaler = preprocessing.StandardScaler().fit(s.values)\n",
        "            new_values = g.values\n",
        "            new_values[:,3:] = scaler.transform(s.values)\n",
        "            ret.append(new_values)\n",
        "\n",
        "    ret = pd.DataFrame(np.asarray(np.vstack(ret)))\n",
        "    ret.columns = X.columns  \n",
        "    return ret"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dSQvEddFwgP"
      },
      "source": [
        "%%time\n",
        "X_train = norm(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMJfSJ8FwgP"
      },
      "source": [
        "%%time\n",
        "X_val = norm(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6WtHnQGFwgQ"
      },
      "source": [
        "%%time\n",
        "X_test = norm(X_test,test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tTf9NjkFwgQ"
      },
      "source": [
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score, balanced_accuracy_score\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.combine import SMOTETomek"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTXTl246FwgR"
      },
      "source": [
        "def leave_1_out(X):\n",
        "    grouped = X.groupby([X.person])\n",
        "\n",
        "    for i, (name,group) in enumerate(grouped):\n",
        "        test = group.copy()\n",
        "        train = X.drop(test.index)\n",
        "\n",
        "        mi = min(train.label.value_counts())\n",
        "        train = train.groupby(train.label, group_keys=False).apply(lambda x: x.sample(min(len(x), mi)))\n",
        "\n",
        "        yield train.index, test.index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgN8IIelFwgR"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42,n_estimators=1000)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "cv = leave_1_out(X_train) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=32)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "print(clf.score(X_val.iloc[:,3:], X_val.label))\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print(accuracy_score(X_val.label, y_pred), balanced_accuracy_score(X_val.label, y_pred))\n",
        "print(f1_score(X_val.label, y_pred))\n",
        "print(matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV_AyrRrFwgS"
      },
      "source": [
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rah2OIKFwgS"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from scipy import stats\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "param_grid = {\n",
        "      'model__eta': [0.01,0.05,0.1,0.3],\n",
        "      'model__max_depth': [3,5,7,9],\n",
        "      'model__gamma': [0,0.1,0.2,0.3,0.4,0.5],\n",
        "      }\n",
        "\n",
        "\n",
        "model = xgb.XGBClassifier(n_estimators=1000)\n",
        "\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['model', model]]\n",
        "                       )\n",
        "cv = leave_1_out(X_train)\n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=4,verbose=1)\n",
        "clf.fit(X_train.iloc[:,3:], X_train.label)\n",
        "\n",
        "y_pred = clf.predict(X_val.iloc[:,3:])\n",
        "print('ACC:' , accuracy_score(X_val.label, y_pred))\n",
        "print('B_ACC:', balanced_accuracy_score(X_val.label, y_pred))\n",
        "print('f1:', f1_score(X_val.label, y_pred), '->',f1_score(X_val.label, y_pred,average=None))\n",
        "print('MCC:', matthews_corrcoef(X_val.label, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSprVWw5FwgT"
      },
      "source": [
        "clf.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MQH3GGcFwgf"
      },
      "source": [
        "X_learning = pd.concat([X_train,X_val],axis=0)\n",
        "X_learning.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XBJxR5WIUrZ"
      },
      "source": [
        "Random Forest predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhurN7b4IW-F"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "n_features = X_train.iloc[:,3:].shape[1]\n",
        "sqrt1_3 = round(pow(n_features,1/3))\n",
        "sqrt3_4 = round(pow(n_features,2/3))\n",
        "params = ['auto',sqrt1_3,sqrt3_4]\n",
        "\n",
        "param_grid = {\n",
        "    'rf__max_features':params,\n",
        "    'rf__min_samples_leaf':[1,3,5]'\n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42,n_estimators=1000)\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['rf', rf]]\n",
        "                       )\n",
        "cv = leave_1_out(X_learning) \n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=32)\n",
        "clf.fit(X_learning.iloc[:,3:], X_learning.label)\n",
        "rf_pred = clf.predict(X_test.iloc[:,2:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb3Id6WQIJBX"
      },
      "source": [
        "XGBOOST predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr-50615Fwgf"
      },
      "source": [
        "%%time\n",
        "from imblearn.pipeline import Pipeline as imbpipeline\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from scipy import stats\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "param_grid = {\n",
        "      'model__eta': [0.01,0.05,0.1,0.3],\n",
        "      'model__max_depth': [3,5,7,9],\n",
        "      'model__gamma': [0,0.1,0.2,0.3,0.4,0.5],\n",
        "      }\n",
        "\n",
        "\n",
        "model = xgb.XGBClassifier(n_estimators=1000)\n",
        "\n",
        "pipeline = imbpipeline(steps = [['var_tresh',VarianceThreshold()],\n",
        "                                ['smote', RandomUnderSampler(random_state=42)],\n",
        "                                ['scaler', StandardScaler()],\n",
        "                                ['model', model]]\n",
        "                       )\n",
        "cv = leave_1_out(X_train)\n",
        "\n",
        "clf = GridSearchCV(pipeline, param_grid, cv=cv, scoring=('balanced_accuracy'), n_jobs=4,verbose=1)\n",
        "clf.fit(X_learning.iloc[:,3:], X_learning.label)\n",
        "xgboost_pred = clf.predict(X_test.iloc[:,2:])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxDEIOrLFwgn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}